{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Part Two: Exploratory data analysis and feature extraction. </h2>\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> In this section, Compute at least 15 such image features (a method for each), including the following (NOTE: At least 10 of these must be scalar features and 2 matrix-based features): (i) image size, (ii) average of the red-channel intensity, (iii) aspect ratio. This will require significant explatoratory research and data analysis. The first one is already implemented for you, and the next two are pre-specified. Additional requirements specfied in pdf. </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import skimage\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "from skimage import feature\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_hdf(\"data.h5\", \"data\")\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display three of the learning set images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = data.groupby('Encoding').agg(lambda x: x.iloc[0])\n",
    "for i in range(3):\n",
    "    skimage.io.imshow(subsample.iloc[i]['Pictures'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.io.imshow(subsample.iloc[0]['Pictures'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide graphical summaries of the sizes of the images, pixel intensities, and class frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize=(6,4), dpi=120)\n",
    "# class frequency\n",
    "class_frequency = data.groupby('Encoding').size()\n",
    "class_frequency.plot.bar()\n",
    "plt.ylabel(\"number of images in each class\")\n",
    "\n",
    "plt.show()\n",
    "# plt.plot(class_frequency[0], class_frequency[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize=(8,6), dpi=120)\n",
    "\n",
    "# sizes of the images\n",
    "def size_image(img):\n",
    "    return img.size\n",
    "data['size'] = data['Pictures'].apply(size_image) \n",
    "sns.boxplot(x='Encoding', y='size', data=data)\n",
    "plt.ylim((0,3e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel intensity\n",
    "# plt.clf()\n",
    "# plt.figure(figsize=(8,6), dpi=120)\n",
    "\n",
    "# sizes of the images\n",
    "def mean_intensity_channel0(img):\n",
    "    return img[:,:,0].mean()\n",
    "def mean_intensity_channel1(img):\n",
    "    return img[:,:,1].mean()\n",
    "def mean_intensity_channel2(img):\n",
    "    return img[:,:,2].mean()\n",
    "def std_intensity_channel0(img):\n",
    "    return img[:,:,0].std()\n",
    "def std_intensity_channel1(img):\n",
    "    return img[:,:,1].std()\n",
    "def std_intensity_channel2(img):\n",
    "    return img[:,:,2].std()\n",
    "\n",
    "data['mean_channel0'] = data['Pictures'].apply(mean_intensity_channel0) \n",
    "data['mean_channel1'] = data['Pictures'].apply(mean_intensity_channel1) \n",
    "data['mean_channel2'] = data['Pictures'].apply(mean_intensity_channel2) \n",
    "data['std_channel0'] = data['Pictures'].apply(std_intensity_channel0) \n",
    "data['std_channel1'] = data['Pictures'].apply(std_intensity_channel1) \n",
    "data['std_channel2'] = data['Pictures'].apply(std_intensity_channel2) \n",
    "\n",
    "sns.boxplot(x='Encoding', y='mean_channel0', data=data)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='mean_channel1', data=data)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='mean_channel2', data=data)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='std_channel0', data=data)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='std_channel1', data=data)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='std_channel2', data=data)\n",
    "plt.show()\n",
    "\n",
    "# plt.ylim((0,8e5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide functions that summarize pixel intensity data (e.g.,https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_table_of_contents_feature2d/py_table_of_contents_feature2d.html#py-table-of-content-feature2d). Compute at least 15 such image features (a method for each), including the following (NOTE: At least 10 of these must be scalar features and 2 matrix-based features): (i) image size, (ii) average of the red-channel intensity, (iii) aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size\n",
    "def feature_size(image):\n",
    "    \"\"\"\n",
    "    return image size\n",
    "    \"\"\"\n",
    "    return image.size\n",
    "\n",
    "def feature_avg_red(image):\n",
    "    \"\"\"\n",
    "    return the average of the red-channel pictures for the image\n",
    "    \"\"\"\n",
    "    return image[:,:,0].mean()\n",
    "\n",
    "def feature_avg_green(image):\n",
    "    \"\"\"\n",
    "    return the average of the green-channel pictures for the image\n",
    "    \"\"\"\n",
    "    return image[:,:,1].mean()\n",
    "\n",
    "def feature_avg_blue(image):\n",
    "    \"\"\"\n",
    "    return the average of the blue-channel pictures for the image\n",
    "    \"\"\"\n",
    "    return image[:,:,2].mean()\n",
    "\n",
    "def feature_aspect_ratio(image):\n",
    "    \"\"\"\n",
    "    return the aspect ratio of the image\n",
    "    \"\"\"\n",
    "    raise image.shape[0] / image.shape[1]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def feature_std_red(image):\n",
    "    \"\"\"\n",
    "    return standard derivation of red channel\n",
    "    \"\"\"\n",
    "    return image[:, :, 0].std()\n",
    "\n",
    "def feature_std_green(image):\n",
    "    \"\"\"\n",
    "    return standard derivation of green channel\n",
    "    \"\"\"\n",
    "    return image[:, :, 1].std()\n",
    "\n",
    "def feature_std_blue(image):\n",
    "    \"\"\"\n",
    "    return standard derivation of blue channel\n",
    "    \"\"\"\n",
    "    return image[:, :, 2].std()\n",
    "\n",
    "def feature_avg_gray(image):\n",
    "    \"\"\"\n",
    "    return mean value of grayscale\n",
    "    \"\"\"\n",
    "    return np.mean(image[:, :, 0] + image[:, :, 1] + image[:, :, 2] / 3)\n",
    "\n",
    "def feature_aspect_ratio(image):\n",
    "    \"\"\"\n",
    "    return aspect ratio of the image, \n",
    "    i.e., the height divided by the width of the image\n",
    "    \"\"\"\n",
    "    return image.shape[0] / image.shape[1]\n",
    "\n",
    "def short_side_resize(image, length=256):\n",
    "    \"\"\"\n",
    "    resize the image to a fixed short side length\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    if height < width:\n",
    "        ratio = length / height\n",
    "    else:\n",
    "        ratio = length / width\n",
    "    new_height = int(height * ratio)\n",
    "    new_width = int(width * ratio)\n",
    "    return skimage.transform.resize(image, (new_height, new_width), mode='reflect', anti_aliasing=True)\n",
    "\n",
    "def center_crop(image, length=224):\n",
    "    \"\"\"\n",
    "    crop the center patch of the image with length * length\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    cx, cy = height // 2, width // 2\n",
    "    lx, ly = cx - length//2, cy - length//2\n",
    "    hx, hy = length + lx, length + ly\n",
    "    return image[lx:hx, ly:hy, :]\n",
    "\n",
    "def feature_harris(image):\n",
    "    \"\"\"\n",
    "    return amount of corners detected by Harris corner detector\n",
    "    \"\"\"\n",
    "    image = center_crop(short_side_resize(image))\n",
    "    gray = skimage.color.rgb2gray(image)\n",
    "    gray = np.array(gray * 255, dtype=np.uint8)\n",
    "    harris = cv2.cornerHarris(gray, blockSize=2, ksize=3, k=0.04)\n",
    "    harris_corners = np.where(harris > 0)\n",
    "    return len(harris_corners[0]) / harris.size\n",
    "\n",
    "def feature_dog(image):\n",
    "    \"\"\"\n",
    "    return the differences of images processed by two Gaussian \n",
    "    filters with different variance (we choose 0.3 and 0.5)\n",
    "    \"\"\"\n",
    "    gray = skimage.color.rgb2gray(image)\n",
    "    g3 = np.asarray(skimage.filters.gaussian(gray, sigma=0.3))\n",
    "    g5 = np.asarray(skimage.filters.gaussian(gray, sigma=0.5))\n",
    "    dog = g3-g5\n",
    "    return sum(sum(dog > 0.05 *dog.max() ))/dog.size\n",
    "\n",
    "def feature_avg_y(image):\n",
    "    \"\"\"\n",
    "    return mean value of luminance Y) \n",
    "    \"\"\"\n",
    "    image = skimage.color.rgb2ycbcr(image)\n",
    "    return image[:, :, 0].mean()\n",
    "\n",
    "\n",
    "def feature_avg_cb(image):\n",
    "    \"\"\"\n",
    "    return mean value of blue chroma component (Cb)\n",
    "    \"\"\"\n",
    "    image = skimage.color.rgb2ycbcr(image)\n",
    "    return image[:, :, 1].mean()\n",
    "\n",
    "def feature_avg_cr(image):\n",
    "    \"\"\"\n",
    "    return mean value of red chroma component (Cr)\n",
    "    \"\"\"\n",
    "    image = skimage.color.rgb2ycbcr(image)\n",
    "    return image[:, :, 2].mean()\n",
    "\n",
    "def feature_std_y(image):\n",
    "    \"\"\"\n",
    "    return standard derivation of luminance (Y)\n",
    "    \"\"\"\n",
    "    image = skimage.color.rgb2ycbcr(image)\n",
    "    return image[:, :, 0].std()\n",
    "\n",
    "def feature_std_cb(image):\n",
    "    \"\"\"\n",
    "    return standard derivation of blue chroma component (Cb)\n",
    "    \"\"\"\n",
    "    image = skimage.color.rgb2ycbcr(image)\n",
    "    return image[:, :, 1].std()\n",
    "\n",
    "def feature_std_cr(image):\n",
    "    \"\"\"\n",
    "    return standard derivation of red chroma component (Cr)\n",
    "    \"\"\"\n",
    "    image = skimage.color.rgb2ycbcr(image)\n",
    "    return image[:, :, 2].std()\n",
    "\n",
    "def feature_avg_hog(image):\n",
    "    \"\"\"\n",
    "    return mean value of Histogram of Oriented Gradients (HOG)\n",
    "    \"\"\"\n",
    "    return skimage.feature.hog(image).mean()\n",
    "\n",
    "def feature_std_hog(image):\n",
    "    \"\"\"\n",
    "    return standard derivation of Histogram of Oriented Gradients (HOG)\n",
    "    \"\"\"\n",
    "    return skimage.feature.hog(image).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We expect all external sources sited, and significant indication of EDA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Graphs </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_frame(df):\n",
    "    # add all features to a DataFrame and drop `Picture` column\n",
    "    df[\"size\"] = df[\"Pictures\"].apply(feature_size)\n",
    "    df[\"avg_red\"] = df[\"Pictures\"].apply(feature_avg_red)\n",
    "    df[\"avg_green\"] = df[\"Pictures\"].apply(feature_avg_green)\n",
    "    df[\"avg_blue\"] = df[\"Pictures\"].apply(feature_avg_blue)\n",
    "    df[\"aspect_ratio\"] = df[\"Pictures\"].apply(feature_aspect_ratio)\n",
    "    df[\"harris\"] = df[\"Pictures\"].apply(feature_harris)\n",
    "    df[\"dog\"] = df[\"Pictures\"].apply(feature_dog)\n",
    "    df[\"avg_y\"] = df[\"Pictures\"].apply(feature_avg_y)\n",
    "    df[\"avg_cb\"] = df[\"Pictures\"].apply(feature_avg_cb)\n",
    "    df[\"avg_cr\"] = df[\"Pictures\"].apply(feature_avg_cr)\n",
    "    df[\"std_y\"] = df[\"Pictures\"].apply(feature_std_y)\n",
    "    df[\"std_cb\"] = df[\"Pictures\"].apply(feature_std_cb)\n",
    "    df[\"std_cr\"] = df[\"Pictures\"].apply(feature_std_cr)\n",
    "    df[\"avg_hog\"] = df[\"Pictures\"].apply(feature_avg_hog)\n",
    "    df[\"std_hog\"] = df[\"Pictures\"].apply(feature_std_hog)\n",
    "    del df[\"Pictures\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = feature_frame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Encoding', y='size', data=feature_df)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='avg_red', data=feature_df)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='avg_green', data=feature_df)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='avg_blue', data=feature_df)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='aspect_ratio', data=feature_df)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='harris', data=feature_df)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='dog', data=feature_df)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='avg_y', data=feature_df)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='avg_cb', data=feature_df)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='avg_cr', data=feature_df)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='std_y', data=feature_df)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='std_cb', data=feature_df)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='std_cr', data=feature_df)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='avg_hog', data=feature_df)\n",
    "plt.show()\n",
    "sns.boxplot(x='Encoding', y='std_hog', data=feature_df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Sources </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> DataFrame Creation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_frame(df):\n",
    "    return df\n",
    "    #Returns data-frame with all the features now inside, and calculated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_frame(data_from_nb1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine how these image features vary between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
